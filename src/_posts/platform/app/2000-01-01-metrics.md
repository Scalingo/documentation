---
title: Application Metrics
nav: Metrics
modified_at: 2026-01-02 12:00:00
tags: app metrics
---

Performance metrics of applications hosted on Scalingo are gathered and
accessible on the web dashboard. Just head to the Metrics tab of your
application to see charts of these key metrics.

This page contains two main parts: **application charts** and **containers
charts**. The viewing period is adjustable to 3h, 12h, 24h, 48h and 72h in the
past.

## Application Charts

{% assign img_url = "https://cdn.scalingo.com/documentation/screenshot_dashboard_metrics_application.png" %}
{% include mdl_img.html %}

The application chart displays global data that are not container specific:
events and routing metrics.

The **Requests per minute** chart show the number of requests the application
receives per minute, the famous **RPM**. The number of server error responses generated by the application (HTTP responses in the 500 range) is displayed on the same chart as red bars.

**Note**: 504 and 503 errors can be generated by our reverse proxy. More
information is available in the [routing documentation][routing-errors].

On top of this chart, all the events that happened during the
viewing period are displayed. This can help you link the application behaviour with events
that happened on the platform, e.g. spot a deployment that contains a memory
leak or follow your application behaviour after a scale operation.

A lot of events are available on the application timeline but only a few relevant are displayed on the metrics view:

- Restart event
- Deploy event
- Scale event

A complete list of events is available in our [developers' documentation](https://developers.scalingo.com/events).

The **Response time** represents the duration between the time a request arrives
at our front servers and the time our front servers receives a response from
your application. It also includes the websocket request times which can be long
request. The requests time chart displays 3 different values regarding the
requests time of an application: the 95th percentile (`p95`), the 99th
percentile (`p99`) and the median. All times are in millisecond. The median of
all your application requests times means that half the requests time are below
this value and half are above. The 95th percentile means that 95% of the
requests time are below this value and 5% are above.

## Container Charts

{% assign img_url = "https://cdn.scalingo.com/documentation/screenshot_dashboard_metrics_containers.png" %}
{% include mdl_img.html %}

The container charts use the container types defined in your [Procfile]({%
post_url platform/app/2000-01-01-procfile %}).

For each container type, two charts are shown. The first one shows the **CPU
usage** and the second one the **memory** and **swap** usage of this type of
container.

The CPU chart may exceed 100% if the application uses more than one core of the CPU.

For the memory chart, the memory (in blue) and swap usage (in red)
are stacked. That way the total memory usage of the application can be
monitored.

The swap usage can increase in two different situations:

- the application uses all the available memory usage. The system starts using
  the swap to allocate new memory block.
- if some memory blocks are never accessed during a long period of time, the
  kernel moves them to the swap, waiting for the next usage. At the first read
  of these blocks, the kernel moves them back to the main memory. Hence, the
  first read is impacted in terms of performance. The impact on the performance
  is different from the previous case where the swap is used until enough memory
  is available.

{% note %}
Protip: Is your application slow? Check your swap usage! If your app
swaps a lot it will significantly alter your application performance. You'd
better reduce its memory usage or use a bigger container size.
{% endnote %}

**Note**: The swap line is only shown if the swap usage exceeds 2% of the
[container memory limit]({% post_url
platform/internals/2000-01-01-container-sizes %}).

If the application has more than one container of a specific type, these charts
show the mean CPU usage / memory consumption of all containers of the same type.

## Behavior when memory and swap are fully consumed

When an application consumes all its allocated memory (RAM + swap), the system applies a protection mechanism called the **OOM Killer** (Out of Memory Killer).

### Sequence of events

1. The application progressively uses all available RAM
2. The system starts using swap space (visible in red on the memory chart)
3. When memory and swap reach 100% usage, the OOM Killer intervenes
4. The application is immediately terminated by the system

### Observable consequences

* **Abrupt termination:** The application stops without a graceful shutdown process
* **Automatic restart:** The container restarts according its configuration
* **Restart event:** A "Restart" event appears in the metrics timeline
* **Data loss:** All non-persisted data in memory is lost

### Prevention and monitoring

To avoid this scenario:

* Regularly monitor memory charts in the Metrics tab
* Set up alerts before reaching memory limits
* Analyse usage spikes in correlation with deployment events
* Consider upgrading to a larger [container size](/platform/internals/container-sizes) if needed

**Note:** The OOM Killer is a system protection mechanism. If your application regularly experiences OOM events, it typically indicates a need for code optimization or increased allocated resources.

## Detailed View

If the application has more than one container of a type defined in its
Procfile, a detailed view of all containers of a type is available. The charts
are exactly the same except that they are per container (and not per container
type). It can greatly help to spot a bugged container and therefore simplify the
debugging process.


[routing-errors]: {% post_url platform/networking/public/2000-01-01-routing %}#http-errors
